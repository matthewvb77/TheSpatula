{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import praw\n",
    "import csv\n",
    "import re\n",
    "import json   \n",
    "import requests\n",
    "import time\n",
    "import mysql.connector\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "reddit = praw.Reddit()\n",
    "\n",
    "class StockPost(object):\n",
    "    def __init__(self, postID, postURL, ups, downs, numComments, stock):\n",
    "        self.postID = postID\n",
    "        self.url = postURL\n",
    "        self.stock = stock\n",
    "        self.ups = ups\n",
    "        self.downs = downs\n",
    "        self.numComments = numComments\n",
    "    \n",
    "    def jsonEnc(self):\n",
    "      return {'stock': self.stock, 'postID': self.postID, 'postURL': self.url, 'ups': self.ups, 'downs': self.downs, 'numComments': self.numComments}\n",
    "\n",
    "def jsonDefEncoder(obj):\n",
    "    if hasattr(obj, 'jsonEnc'):\n",
    "        return obj.jsonEnc()\n",
    "    else: #some default behavior\n",
    "        return obj.__dict__\n",
    "\n",
    " ### DATABASE FUNCTIONS ###\n",
    "\n",
    "    # returns connection object #\n",
    "def connect_to_db(db_name):\n",
    "    cnx = mysql.connector.connect(\n",
    "    user='root',\n",
    "    password='chalkHorseMountain',\n",
    "    host='localhost',\n",
    "    database=db_name\n",
    "    )\n",
    "    return cnx\n",
    "    \n",
    "    # returns boolean #\n",
    "def table_exists(cursor, tbl_name):\n",
    "    cursor.execute(\"\"\"\n",
    "        SELECT COUNT(*)\n",
    "        FROM information_schema.tables\n",
    "        WHERE table_schema = DATABASE()\n",
    "        AND table_name = \\\"\"\"\" + tbl_name + \"\"\"\\\";\n",
    "    \"\"\")\n",
    "    \n",
    "    if cursor.fetchone()[0] == 1:\n",
    "        return True\n",
    "    return False\n",
    "    \n",
    "    \n",
    "class SubredditScraper:\n",
    "\n",
    "    def __init__(self, sub, sort='new', lim=900):\n",
    "        self.sub = sub\n",
    "        self.sort = sort\n",
    "        self.lim = lim\n",
    "\n",
    "        #print(\n",
    "            #f'SubredditScraper instance created with values '\n",
    "            #f'sub = {sub}, sort = {sort}, lim = {lim}')\n",
    "\n",
    "    def set_sort(self):\n",
    "        if self.sort == 'new':\n",
    "            return self.sort, reddit.subreddit(self.sub).new(limit=self.lim)\n",
    "        elif self.sort == 'top':\n",
    "            return self.sort, reddit.subreddit(self.sub).top(limit=self.lim)\n",
    "        elif self.sort == 'hot':\n",
    "            return self.sort, reddit.subreddit(self.sub).hot(limit=self.lim)\n",
    "        else:\n",
    "            self.sort = 'hot'\n",
    "            print('Sort method was not recognized, defaulting to hot.')\n",
    "            return self.sort, reddit.subreddit(self.sub).hot(limit=self.lim)\n",
    "\n",
    "    def get_posts(self):\n",
    "\n",
    "        stockTickers = {}\n",
    "        with open('./../Tickers/tickers_stocks.csv', mode='r') as infile:\n",
    "            reader = csv.reader(infile)\n",
    "            for row in reader:\n",
    "                stockTickers[row[0].split(',')[0]] = {}\n",
    "        \"\"\"Get unique posts from a specified subreddit.\"\"\"\n",
    "\n",
    "        # Attempt to specify a sorting method.\n",
    "        sort, subreddit = self.set_sort()\n",
    "\n",
    "        print(f'Collecting information from r/{self.sub}.')\n",
    "        \n",
    "        ## Search posts for tickers ##\n",
    "        relevantPosts = []\n",
    "        # convert subreddit listing generator -> list\n",
    "        subreddit = list(subreddit)\n",
    "        for i in tqdm(range(len(subreddit)), desc=\"Scraping Posts\"):\n",
    "            post = subreddit[i]\n",
    "\n",
    "            if post.link_flair_text != 'Meme':\n",
    "                for stock in stockTickers.keys():\n",
    "                    if(re.search(r'\\s+\\$?' + stock + r'\\$?\\s+', post.selftext) or re.search(r'\\s+\\$?' + stock + r'\\$?\\s+',  post.title)):\n",
    "                        stockTickers[stock][post.id] = StockPost(post.id, post.permalink, post.ups, post.downs, post.num_comments, stock)\n",
    "        \n",
    "        ## Upload data to db ##\n",
    "        cnx = connect_to_db(\"TheSpatula\")\n",
    "        mycursor = cnx.cursor()\n",
    "        assert mycursor\n",
    "        assert table_exists(mycursor, \"reddit\")\n",
    "        \n",
    "        for stock in stockTickers.keys():\n",
    "            if (len(stockTickers[stock]) > 0):\n",
    "                for post in stockTickers[stock]:\n",
    "                    \n",
    "                    relevantPosts.append(stockTickers[stock][post]) \n",
    "        json_object = json.dumps(relevantPosts, default=jsonDefEncoder, indent = 4)   \n",
    "        print(json_object)  \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    SubredditScraper('wallstreetbets', lim=20, sort='hot').get_posts()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
