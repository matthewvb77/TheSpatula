{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b20679df8164509b108527800407235",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='[2/3] Scraping Vids'), FloatProgress(value=0.0, max=20.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "beccfe3605444507ae30017b07d7e96f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='[3/3] Updating Database'), FloatProgress(value=0.0, max=20.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2Dxt1RYRjj4\n",
      "3200\n",
      "2021-05-20\n",
      "BjCgfipwyI0\n",
      "19000\n",
      "2021-05-20\n",
      "HrX8zeQ5LAU\n",
      "1800\n",
      "2021-05-20\n",
      "yZzvpwrbXLA\n",
      "283\n",
      "2021-05-20\n",
      "OTpVk76a87M\n",
      "3100\n",
      "2021-05-20\n",
      "6JqIpkhv72w\n",
      "14000\n",
      "2021-05-19\n",
      "PXDwLvRtVBU\n",
      "9000\n",
      "2021-05-20\n",
      "n1XxD7hLKdo\n",
      "5700\n",
      "2021-05-20\n",
      "2DLek8pa4iI\n",
      "103000\n",
      "2021-04-29\n",
      "O3PdsJbFm0w\n",
      "4600\n",
      "2021-05-19\n",
      "LqrW7bN2_2M\n",
      "2300\n",
      "2021-05-20\n",
      "Gl7sa9xSLYs\n",
      "26000\n",
      "2021-05-18\n",
      "PCQedJJDwqg\n",
      "3200\n",
      "2021-05-19\n",
      "SNsSjREwIoo\n",
      "19000\n",
      "2021-05-18\n",
      "kntV1hbJBlU\n",
      "27000\n",
      "2021-05-17\n",
      "PvhgjkMmXc4\n",
      "15000\n",
      "2021-05-18\n",
      "aqrDpQlG9XM\n",
      "29000\n",
      "2021-05-19\n",
      "IwthonKJsHU\n",
      "2100\n",
      "2021-05-19\n",
      "3ngxKYha0Ik\n",
      "76000\n",
      "2021-05-13\n",
      "p5dvzU_J-lc\n",
      "44000\n",
      "2021-05-16\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "import pyautogui\n",
    "\n",
    "import csv\n",
    "import json\n",
    "import time\n",
    "import mysql.connector\n",
    "\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "class StockVid(object):\n",
    "    def __init__(self, href, date, views):\n",
    "        self.post_id = href\n",
    "        self.date = date\n",
    "        self.views = views\n",
    "    \n",
    "    def jsonEnc(self):\n",
    "      return {'stock': self.stock, 'date': self.date, 'views': self.views}\n",
    "\n",
    "def jsonDefEncoder(obj):\n",
    "    if hasattr(obj, 'jsonEnc'):\n",
    "        return obj.jsonEnc()\n",
    "    else: #some default behavior\n",
    "        return obj.__dict__\n",
    "\n",
    "    \n",
    "### DATABASE FUNCTIONS ###\n",
    "\n",
    "    # returns connection object #\n",
    "def connect_to_db(db_name):\n",
    "    cnx = mysql.connector.connect(\n",
    "    user='root',\n",
    "    password='chalkHorseMountain',\n",
    "    host='localhost',\n",
    "    database=db_name\n",
    "    )\n",
    "    return cnx\n",
    "    \n",
    "    # returns boolean #\n",
    "def table_exists(cursor, tbl_name):\n",
    "    cursor.execute(f\"\"\"\n",
    "        SELECT COUNT(*)\n",
    "        FROM information_schema.tables\n",
    "        WHERE table_schema = DATABASE()\n",
    "        AND table_name = \"{tbl_name}\";\n",
    "    \"\"\")\n",
    "    \n",
    "    if cursor.fetchone()[0] == 1:\n",
    "        return True\n",
    "    return False\n",
    "     \n",
    "def get_date(post):\n",
    "    try:\n",
    "        posted = post.find_element_by_xpath(\".//*[@id='metadata-line']/span[2]\").text\n",
    "        \n",
    "        if \"just now\" in posted:\n",
    "            return today.strftime('%Y-%m-%d')\n",
    "    except:\n",
    "        ## If live, return today\n",
    "        return today.strftime('%Y-%m-%d')\n",
    "        \n",
    "    # Example: today = [\"2021\", \"05\", \"15\"]\n",
    "    today = datetime.today()\n",
    "    \n",
    "    # Example: vid_time_data = [5, \"hours\", \"ago\"]\n",
    "    vid_time_data = posted.split()\n",
    "    \n",
    "    # Remove \"Streamed\"\n",
    "    if vid_time_data[0] == \"Streamed\":\n",
    "        vit_time_data = vid_time_data[1:]\n",
    "\n",
    "    if \"minute\" in posted:\n",
    "        return (today - timedelta(minutes=int(vid_time_data[0]))).strftime('%Y-%m-%d')\n",
    "    \n",
    "    if \"hour\" in posted:\n",
    "        return (today - timedelta(hours=int(vid_time_data[0]))).strftime('%Y-%m-%d')\n",
    "    \n",
    "    if \"day\" in posted:\n",
    "        return (today - timedelta(days=int(vid_time_data[0]))).strftime('%Y-%m-%d')\n",
    "\n",
    "    if \"week\" in posted:\n",
    "        return (today - timedelta(days=7*int(vid_time_data[0]))).strftime('%Y-%m-%d')\n",
    "\n",
    "    if \"month\" in posted:\n",
    "        return (today - timedelta(days=30*int(vid_time_data[0]))).strftime('%Y-%m-%d')\n",
    "\n",
    "    if \"year\" in posted:\n",
    "        return (today - timedelta(days=365*int(vid_time_data[0]))).strftime('%Y-%m-%d')\n",
    "    \n",
    "            \n",
    "    raise Exception(f\"Invalid post time-metadata: {vid_time_data}\")\n",
    "    \n",
    "    \n",
    "def get_views(post):\n",
    "    views_data = post.find_element_by_xpath(\".//*[@id='metadata-line']/span[1]\").text\n",
    "    views_data = views_data.split()\n",
    "    views_data = views_data[0]\n",
    "    \n",
    "    if views_data[-1] == \"K\":\n",
    "        num_views = int(float(views_data[:-1]) * 1000)\n",
    "        \n",
    "    elif views_data[-1] == \"M\":\n",
    "        num_views = int(float(views_data[:-1]) * 1000000)\n",
    "    \n",
    "    elif views_data[-1] == \"B\":\n",
    "        num_views = int(float(views_data[:-1]) * 1000000000)\n",
    "        \n",
    "    else:\n",
    "        num_views = int(views_data)\n",
    "    \n",
    "    return num_views\n",
    "    \n",
    "    \n",
    "class youtubeScraper:\n",
    "\n",
    "    def get_vids(self, stock):\n",
    "        \n",
    "        stockTickers = {}\n",
    "        stockTickers[stock] = {}\n",
    "        relevantPosts = []\n",
    "        \n",
    "        driver = webdriver.Chrome('C:/WebDriver/chromedriver')\n",
    "        driver.get(\"https://www.youtube.com/results?search_query=\" + stock)\n",
    "       \n",
    "    \n",
    "        ## Begin Scrolling ##\n",
    "        start = time.perf_counter()\n",
    "        print(\"[1/3] Scrolling To Bottom\", end=' ')\n",
    "        while(True):\n",
    "            try:\n",
    "                driver.find_element_by_xpath(\"//*[@id='message'][text()='No more results']\")\n",
    "                break\n",
    "            except:\n",
    "                pyautogui.press('pagedown')\n",
    "                continue\n",
    "             \n",
    "            break\n",
    "            \n",
    "        end = time.perf_counter()\n",
    "        p1_time = divmod(int(end-start), 60)\n",
    "        print(\"[{:02}:{:02}]\".format(p1_time[0], p1_time[1]))\n",
    "        \n",
    "            \n",
    "        ## Begin Scraping ##\n",
    "        \n",
    "        all_posts = driver.find_elements_by_xpath(\"//div[@ID='contents']/ytd-video-renderer\")\n",
    "        \n",
    "        for i in tqdm(range(len(all_posts)), desc = '[2/3] Scraping Vids'):\n",
    "            post = all_posts[i]\n",
    "            \n",
    "            url = post.find_element_by_xpath(\".//*[@id='video-title']\").get_attribute(\"href\")\n",
    "            # The last 11 chars of the url is the unique key\n",
    "            post_id = url[-11:]\n",
    "            num_views = get_views(post)\n",
    "            post_date = get_date(post)\n",
    "            \n",
    "            stockTickers[stock][i] = StockVid(post_id, post_date, num_views) \n",
    "            \n",
    "        driver.close()\n",
    "        \n",
    "        ## Begin Formatting Results ##\n",
    "        if(len(stockTickers[stock]) > 0):\n",
    "            for post in stockTickers[stock]:\n",
    "                relevantPosts.append(stockTickers[stock][post])\n",
    "        #json_object = json.dumps(relevantPosts, default=jsonDefEncoder, indent = 4)\n",
    "        #print(json_object)\n",
    "        \n",
    "        ## Updating Database ##\n",
    "        \n",
    "        cnx = connect_to_db(\"TheSpatula\")\n",
    "        mycursor = cnx.cursor()\n",
    "        assert mycursor\n",
    "        \n",
    "        # If proper table doesnt exist, make one\n",
    "        if(table_exists(mycursor, f\"youtube_{stock}\")):\n",
    "            pass\n",
    "        else:\n",
    "            mycursor.execute(f\"\"\"\n",
    "                CREATE TABLE youtube_{stock} (\n",
    "                    post_id VARCHAR(11), \n",
    "                    num_views INT, \n",
    "                    date_posted DATE, \n",
    "                    PRIMARY KEY (post_id)\n",
    "                );\n",
    "            \"\"\")\n",
    "            cnx.commit()\n",
    "            \n",
    "        assert table_exists(mycursor, f\"youtube_{stock}\")\n",
    "        \n",
    "        for x in tqdm(range(len(relevantPosts)), desc=\"[3/3] Updating Database\"):\n",
    "            post = relevantPosts[x]\n",
    "            \n",
    "            ## Add post, if it exists already, update post ##\n",
    "            mycursor.execute(f\"\"\"\n",
    "            INSERT INTO youtube_{stock} (post_id, num_views, date_posted) \n",
    "            VALUES(\"{post.post_id}\", {post.views}, \"{post.date}\")\n",
    "            ON DUPLICATE KEY UPDATE num_views={post.views}\n",
    "            ;\"\"\")\n",
    "            \n",
    "            cnx.commit()\n",
    "            \n",
    "        \n",
    "if __name__ == \"__main__\":\n",
    "    youtubeScraper().get_vids('safemoon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
