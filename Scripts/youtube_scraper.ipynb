{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "import pyautogui\n",
    "\n",
    "import csv\n",
    "import json\n",
    "import time\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "class StockVid(object):\n",
    "    def __init__(self, stock, date, views):\n",
    "        self.stock = stock\n",
    "        self.date = date\n",
    "        self.views = views\n",
    "    \n",
    "    def jsonEnc(self):\n",
    "      return {'stock': self.stock, 'date': self.date, 'views': self.views}\n",
    "\n",
    "def jsonDefEncoder(obj):\n",
    "    if hasattr(obj, 'jsonEnc'):\n",
    "        return obj.jsonEnc()\n",
    "    else: #some default behavior\n",
    "        return obj.__dict__\n",
    "\n",
    "    \n",
    "### DATABASE FUNCTIONS ###\n",
    "\n",
    "    # returns connection object #\n",
    "def connect_to_db(db_name):\n",
    "    cnx = mysql.connector.connect(\n",
    "    user='root',\n",
    "    password='chalkHorseMountain',\n",
    "    host='localhost',\n",
    "    database=db_name\n",
    "    )\n",
    "    return cnx\n",
    "    \n",
    "    # returns boolean #\n",
    "def table_exists(cursor, tbl_name):\n",
    "    cursor.execute(\"\"\"\n",
    "        SELECT COUNT(*)\n",
    "        FROM information_schema.tables\n",
    "        WHERE table_schema = DATABASE()\n",
    "        AND table_name = \\\"\"\"\" + tbl_name + \"\"\"\\\";\n",
    "    \"\"\")\n",
    "    \n",
    "    if cursor.fetchone()[0] == 1:\n",
    "        return True\n",
    "    return False\n",
    "     \n",
    "    \n",
    "class youtubeScraper:\n",
    "\n",
    "    def get_vids(self, stock):\n",
    "        \n",
    "        stockTickers = {}\n",
    "        stockTickers[stock] = {}\n",
    "        relevantVids = []\n",
    "        \n",
    "        driver = webdriver.Chrome('C:/WebDriver/chromedriver')\n",
    "        driver.get(\"https://www.youtube.com/results?search_query=\" + stock)\n",
    "       \n",
    "    \n",
    "        ## Begin Scrolling ##\n",
    "        start = time.perf_counter()\n",
    "        print(\"[1/2] Scrolling To Bottom\", end=' ')\n",
    "        while(True):\n",
    "            try:\n",
    "                driver.find_element_by_xpath(\"//*[@id='message'][text()='No more results']\")\n",
    "                break\n",
    "            except:\n",
    "                pyautogui.press('pagedown')\n",
    "                continue\n",
    "             \n",
    "            break\n",
    "            \n",
    "        end = time.perf_counter()\n",
    "        p1_time = divmod(int(end-start), 60)\n",
    "        print(\"[{:02}:{:02}]\".format(p1_time[0], p1_time[1]))\n",
    "        \n",
    "            \n",
    "        ## Begin Scraping ##\n",
    "        cnx = connect_to_db(\"TheSpatula\")\n",
    "        mycursor = cnx.cursor()\n",
    "        assert mycursor\n",
    "        assert table_exists(mycursor, \"reddit\")\n",
    "        \n",
    "        all_vids = driver.find_elements_by_xpath(\"//div[@ID='contents']/ytd-video-renderer\")\n",
    "        \n",
    "        for i in tqdm(range(len(all_vids)), desc = '[2/2] Scraping Vids'):\n",
    "            vid = all_vids[i]\n",
    "            vid_views = vid.find_element_by_xpath(\".//*[@id='metadata-line']/span[1]\").text\n",
    "            \n",
    "            try:\n",
    "                vid_date = vid.find_element_by_xpath(\".//*[@id='metadata-line']/span[2]\").text\n",
    "            except:\n",
    "                vid_date = \"live\"\n",
    "                \n",
    "            stockTickers[stock][i] = StockVid(stock, vid_date, vid_views) \n",
    "            \n",
    "        driver.close()\n",
    "        \n",
    "        ## Begin Formatting Results ##\n",
    "        if(len(stockTickers[stock]) > 0):\n",
    "            for post in stockTickers[stock]:\n",
    "                relevantVids.append(stockTickers[stock][post])\n",
    "        json_object = json.dumps(relevantVids, default=jsonDefEncoder, indent = 4)\n",
    "        \n",
    "        print(json_object) \n",
    "        \n",
    "        \n",
    "if __name__ == \"__main__\":\n",
    "    youtubeScraper().get_vids('safemoon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating youtube_<stock> Table\n",
    "mycursor.execute(f\"\"\"\n",
    "    CREATE TABLE youtube_{stock} (\n",
    "        post_id INT, num_views INT, date_posted DATE\n",
    "    );\n",
    "    \"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
