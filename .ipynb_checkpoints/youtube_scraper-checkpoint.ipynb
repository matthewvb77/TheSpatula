{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "import pyautogui\n",
    "\n",
    "import csv\n",
    "import re\n",
    "import json\n",
    "\n",
    "\n",
    "class StockVid(object):\n",
    "    def __init__(self, stock, date, views):\n",
    "        self.stock = stock\n",
    "        self.date = date\n",
    "        self.views = views\n",
    "    \n",
    "    def jsonEnc(self):\n",
    "      return {'stock': self.stock, 'date': self.date, 'views': self.views}\n",
    "\n",
    "def jsonDefEncoder(obj):\n",
    "    if hasattr(obj, 'jsonEnc'):\n",
    "        return obj.jsonEnc()\n",
    "    else: #some default behavior\n",
    "        return obj.__dict__\n",
    "\n",
    "    \n",
    "class youtubeScraper:\n",
    "    \n",
    "    def __init__(self):\n",
    "                 \n",
    "                 \n",
    "    def get_vids(self):\n",
    "        stockTickers = {}\n",
    "        \n",
    "        with open('tickers_crypto.csv', mode='r') as infile:\n",
    "            reader = csv.reader(infile)\n",
    "            for row in reader:\n",
    "                stockTickers[row[0].split(',')[0]] = {}\n",
    "        \"\"\"Get unique posts from a specified subreddit.\"\"\"\n",
    "\n",
    "        # relevantPosts = []\n",
    "        # i = 0\n",
    "        # for post in subreddit:\n",
    "        #     i = i + 1\n",
    "        #     print(f'{i}/{self.lim}')\n",
    "        #     if post.link_flair_text != 'Meme':\n",
    "        #         for stock in stockTickers.keys():\n",
    "        #             if(re.search(r'\\s+\\$?' + stock + r'\\$?\\s+', post.selftext) or re.search(r'\\s+\\$?' + stock + r'\\$?\\s+',  post.title)):\n",
    "        #                 stockTickers[stock][post.id] = StockPost(post.id, post.permalink, post.ups, post.downs, post.num_comments, stock)\n",
    "        # \n",
    "        # for stock in stockTickers.keys():\n",
    "        #     if (len(stockTickers[stock]) > 0):\n",
    "        #         for post in stockTickers[stock]:\n",
    "        #             relevantPosts.append(stockTickers[stock][post]) \n",
    "        # json_object = json.dumps(relevantPosts, default=jsonDefEncoder, indent = 4)   \n",
    "        # print(json_object) \n",
    "                 \n",
    "        driver = webdriver.Chrome('C:/WebDriver/chromedriver')\n",
    "        relevantVids = []\n",
    "        i = 0\n",
    "        for stock in stockTickers.keys():\n",
    "            driver.get(\"https://www.youtube.com/results?search_query=\" + stock)\n",
    "                 \n",
    "            # while \"no more results\" is not displayed\n",
    "            while(True):\n",
    "                try:\n",
    "                    driver.find_element_by_xpath(\"/html/body/ytd-app/div/ytd-page-manager/ytd-search/div[1]/ytd-two-column-search-results-renderer/div/ytd-section-list-renderer/div[2]/ytd-item-section-renderer[30]/div[3]/ytd-message-renderer/yt-formatted-string[1]\")\n",
    "                except:\n",
    "                    pyautogui.press('pagedown')\n",
    "                    continue\n",
    "                 \n",
    "                break\n",
    "            # page is at bottom\n",
    "            all_vids = driver.find_elements_by_xpath(\"//div[@ID='contents']/ytd-video-renderer\")\n",
    "                 \n",
    "            for vid in all_vids:\n",
    "                 vid_date = vid.find_element_by_xpath(\"//*[@id='metadata-line']/span[2]\").text\n",
    "                 vid_views = vid.find_element_by_xpath(\"//*[@id='metadata-line']/span[1]\").text\n",
    "                 stockTickers[stock] = StockPost(post.id, post.permalink, post.ups, post.downs, post.num_comments, stock)\n",
    "                 \n",
    "                 \n",
    "                 \n",
    "                 \n",
    "                 \n",
    "                 \n",
    "                 \n",
    "                 \n",
    "        \n",
    "        \n",
    "        \n",
    "if __name__ == \"__main__\":\n",
    "    youtubeScraper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
